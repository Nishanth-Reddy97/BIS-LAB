
# Bagasse Ash Concrete Optimization using PSO


import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.neural_network import MLPRegressor
import matplotlib.pyplot as plt

# STEP 1: Generate synthetic dataset (replace with real data if available)

np.random.seed(42)
n_samples = 300

cement = np.random.uniform(200, 450, n_samples)
bagasse_ash = np.random.uniform(0, 30, n_samples)  # replacement percentage
water_binder = np.random.uniform(0.3, 0.6, n_samples)
fine_agg = np.random.uniform(600, 900, n_samples)
coarse_agg = np.random.uniform(1000, 1300, n_samples)
curing_days = np.random.choice([7, 14, 28, 56, 90], n_samples)

# Simulated nonlinear compressive strength function
strength = (
    0.06 * cement
    - 0.4 * bagasse_ash
    + 20 * (1 - water_binder)
    + 0.005 * fine_agg
    + 0.003 * coarse_agg
    + 0.2 * np.log(curing_days)
    + np.random.normal(0, 2, n_samples)
)

data = pd.DataFrame({
    'Cement': cement,
    'BagasseAsh_%': bagasse_ash,
    'WaterBinder': water_binder,
    'FineAgg': fine_agg,
    'CoarseAgg': coarse_agg,
    'CuringDays': curing_days,
    'Strength': strength
})


# STEP 2: Prepare data

X = data.drop(columns=['Strength'])
y = data['Strength']

scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# STEP 3: Train prediction model (Neural Network)

model = MLPRegressor(hidden_layer_sizes=(64, 32), activation='relu', max_iter=2000, random_state=42)
model.fit(X_train, y_train)

print("Model R² on test data:", model.score(X_test, y_test))


# STEP 4: Particle Swarm Optimization


# PSO parameters
n_particles = 30
n_iterations = 100
dim = X.shape[1]  # number of features
w = 0.7           # inertia
c1 = 1.5          # cognitive
c2 = 1.5          # social

# Search bounds (same scale as normalized input)
lb = np.zeros(dim)
ub = np.ones(dim)

# Initialize particles
pos = np.random.uniform(lb, ub, (n_particles, dim))
vel = np.random.uniform(-0.1, 0.1, (n_particles, dim))

# Evaluate initial fitness
def fitness(x):
    x = x.reshape(1, -1)
    return -model.predict(x)[0]  # negative for minimization (we want max strength)

pbest_pos = pos.copy()
pbest_val = np.array([fitness(p) for p in pos])
gbest_idx = np.argmin(pbest_val)
gbest_pos = pbest_pos[gbest_idx].copy()
gbest_val = pbest_val[gbest_idx]

fitness_history = []

# PSO main loop
for t in range(n_iterations):
    for i in range(n_particles):
        # Update velocity and position
        r1, r2 = np.random.rand(dim), np.random.rand(dim)
        vel[i] = (
            w * vel[i]
            + c1 * r1 * (pbest_pos[i] - pos[i])
            + c2 * r2 * (gbest_pos - pos[i])
        )
        pos[i] += vel[i]
        pos[i] = np.clip(pos[i], lb, ub)

        # Evaluate new fitness
        f = fitness(pos[i])
        if f < pbest_val[i]:
            pbest_val[i] = f
            pbest_pos[i] = pos[i].copy()

    # Update global best
    gbest_idx = np.argmin(pbest_val)
    if pbest_val[gbest_idx] < gbest_val:
        gbest_val = pbest_val[gbest_idx]
        gbest_pos = pbest_pos[gbest_idx].copy()

    fitness_history.append(-gbest_val)


# STEP 5: Show Results

print("\nOptimal normalized mix (scaled):", gbest_pos)
decoded = scaler.inverse_transform(gbest_pos.reshape(1, -1))[0]
print("\nOptimal mix design (real units):")
print(f"Cement: {decoded[0]:.2f} kg/m³")
print(f"Bagasse Ash: {decoded[1]:.2f} %")
print(f"Water/Binder: {decoded[2]:.3f}")
print(f"Fine Aggregate: {decoded[3]:.2f} kg/m³")
print(f"Coarse Aggregate: {decoded[4]:.2f} kg/m³")
print(f"Curing Days: {decoded[5]:.0f} days")

print(f"\nPredicted Maximum Compressive Strength: {-gbest_val:.2f} MPa")

# Plot convergence
